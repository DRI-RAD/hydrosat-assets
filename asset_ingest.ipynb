{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbbc425e-0064-4487-accd-aa47ecdc087e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import json\n",
    "# import logging\n",
    "import os\n",
    "import pprint\n",
    "import base64\n",
    "\n",
    "\n",
    "import ee\n",
    "from google.cloud import storage\n",
    "import pystac\n",
    "from pystac_client import Client\n",
    "import requests\n",
    "\n",
    "import IPython.display\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "endpoint = 'https://fusion-stac.hydrosat.com/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92327507-ef6f-45b3-b83e-bdae3f8467fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "ee.Initialize(project='dri-hydrosat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f6c0cc1-8d05-45ed-88f9-b568ffc4ef20",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('creds.json') as f:\n",
    "    creds = json.loads(f.read())\n",
    "\n",
    "userpass = f\"{creds['username']}:{creds['password']}\"\n",
    "b64 = base64.b64encode(userpass.encode()).decode()\n",
    "headers = {'Authorization':'Basic ' + b64}\n",
    "\n",
    "cat_url = 'https://stac.hydrosat.com'\n",
    "catalog = Client.open(cat_url, headers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "626d6c27-b16f-451e-abfa-c7a5030e0749",
   "metadata": {},
   "outputs": [],
   "source": [
    "workspace = '/Users/Charles.Morton@dri.edu/Projects/hydrosat-assets/geotiffs/'\n",
    "# workspace = os.getcwd()\n",
    "\n",
    "project_id = 'dri-hydrosat'\n",
    "bucket_name = 'hydrosat'\n",
    "\n",
    "# Output band names\n",
    "lst_band_name = 'lst'\n",
    "qa_band_name = 'qa'\n",
    "\n",
    "overwrite_flag = False\n",
    "\n",
    "start_date = \"2019-01-01T00:00:00Z\"\n",
    "end_date = \"2020-01-01T00:00:00Z\"\n",
    "\n",
    "bbaoi = [-111.51, 36.85, -110.36, 37.86]  # Powell\n",
    "#aoi = {\"type\": \"Point\", \"coordinates\": [-120.0, 38.8]}     # Tahoe\n",
    "#aoi = {\"type\": \"Point\", \"coordinates\": [-111.3, 37.06]}    # Powell\n",
    "#aoi = {\"type\": \"Point\", \"coordinates\": [-114.75, 36.08]}   # Mead\n",
    "#aoi = {\"type\": \"Point\", \"coordinates\": [-114.65, 35.43]}   # Mojave\n",
    "\n",
    "collection = \"starfm_predictions_modis_landsat\"\n",
    "# collection = \"pydms_sharpened_landsat\"\n",
    "# collection = \"pydms_sharpened_modis\"\n",
    "# collection = \"pydms_sharpened_viirs\"\n",
    "print(f'Collection: {collection}\\n')\n",
    "\n",
    "search = catalog.search(\n",
    "    bbox = bbaoi,\n",
    "    #intersects = aoi,\n",
    "    datetime = [start_date, end_date],\n",
    "    collections = [collection],\n",
    "    max_items = 1000,\n",
    ")\n",
    "#items = search.get_all_items()\n",
    "items = search.item_collection()\n",
    "itemjson = items.to_dict()\n",
    "print(f'Number of catalog items: {len(items)}\\n')\n",
    "\n",
    "\n",
    "# Get the list of local file names (not paths)\n",
    "file_list = [\n",
    "    item\n",
    "    # os.path.join(root, item)\n",
    "    for root, dirs, files in os.walk(workspace, topdown=False)\n",
    "    for item in files\n",
    "    if item.endswith('.tif')\n",
    "]\n",
    "\n",
    "\n",
    "asset_coll = f'projects/{project_id}/assets/{collection}'\n",
    "if not ee.data.getInfo(asset_coll):\n",
    "    print('\\nCollection does not exist and will be built\\n  {}'.format(asset_coll))\n",
    "    input('Press ENTER to continue')\n",
    "    ee.data.createAsset({'type': 'IMAGE_COLLECTION'}, asset_coll)\n",
    "\n",
    "# TODO: Get the list of assets IDs instead of calling ee.data.getInfo in the loop\n",
    "# asset_id_list = ee.ImageCollection(asset_coll).aggregate_array('system:index').getInfo()\n",
    "\n",
    "\n",
    "storage_client = storage.Client(project=project_id)\n",
    "\n",
    "\n",
    "for item in itemjson[\"features\"]:\n",
    "\n",
    "    # pprint.pprint(item['assets'])\n",
    "    # break\n",
    "    \n",
    "    lst_image_url = item[\"assets\"][\"lst\"][\"href\"]\n",
    "    qa_image_url = item[\"assets\"][\"combined_qa\"][\"href\"]\n",
    "\n",
    "    collection = lst_image_url.split('?', 1)[0].split('/')[-4]\n",
    "    year = lst_image_url.split('?', 1)[0].split('/')[-3]\n",
    "    #temp = lst_image_url.split('?', 1)[0].split('/')[-2]\n",
    "    \n",
    "    lst_file_name = lst_image_url.split('?', 1)[0].split('/')[-1]\n",
    "    #.replace('.tif', f'_{lst_band_name}.tif')\n",
    "    qa_file_name = qa_image_url.split('?', 1)[0].split('/')[-1]\n",
    "    #.replace('.tif', f'_{qa_band_name}.tif')\n",
    "    print(f'{lst_file_name}')\n",
    "    print(f'{qa_file_name}')\n",
    "    # input('ENTER')\n",
    "\n",
    "    year_folder = os.path.join(workspace, collection, year)\n",
    "    lst_local_path = os.path.join(year_folder, lst_file_name)\n",
    "    qa_local_path = os.path.join(year_folder, qa_file_name)\n",
    "    lst_bucket_path = f'gs://{bucket_name}/{collection}/{year}/{lst_file_name}'\n",
    "    qa_bucket_path = f'gs://{bucket_name}/{collection}/{year}/{qa_file_name}'\n",
    "    \n",
    "    image_dt = datetime.fromisoformat(item['properties']['datetime'])\n",
    "    image_id = f'{item[\"properties\"][\"mgrs_tile\"]}_{image_dt.strftime(\"%Y%m%d\")}'\n",
    "    asset_id = f'projects/{project_id}/assets/{collection}/{image_id}'\n",
    "    print(asset_id)\n",
    "\n",
    "\n",
    "    # Get the properties dictionary from the item\n",
    "    properties = item['properties']\n",
    "    properties['file_name'] = file_name\n",
    "    properties['date_ingested'] = f'{datetime.today().strftime(\"%Y-%m-%d\")}'\n",
    "\n",
    "    # Converting properties to string\n",
    "    # This is needed especially for the nested dictionary properties\n",
    "    # TODO: Check if JSON dump would be better for this\n",
    "    str_properties = [\n",
    "        'processing:time_of_day_range', 'processing:nrt', 'processing:overwrite_outputs',\n",
    "        'processing:public', 'processing:sr_only', 'processing:test_mode',\n",
    "        'processing:qa_screen_opts', 'processing:starfm_opts', \n",
    "        'processing:pydms_common_opts', 'processing:pydms_dt_opts', \n",
    "        'processing:starfm_opts', 'hydrosat:fusion_inputs',\n",
    "    ]\n",
    "    for p in str_properties:\n",
    "        if p in properties.keys():\n",
    "            properties[p] = str(properties[p])\n",
    "    \n",
    "    # TODO: Check for a cleaner way to rename properties in a dictionary\n",
    "    del_properties = [\n",
    "        'processing:software', 'processing:pydms_nn_opts', 'processing:pydms_sknn_opts', 'processing:lineage', \n",
    "    ]\n",
    "    new_properties = {}\n",
    "    for k, v in properties.items():\n",
    "        if ((\":\" in k) or ('-' in k)) and (k not in del_properties):\n",
    "            new_properties[k.replace(':', '_').replace('-', '_')] = v\n",
    "            del_properties.append(k)\n",
    "    for k in del_properties:\n",
    "        del properties[k] \n",
    "    properties.update(new_properties)\n",
    "    #pprint.pprint(properties)\n",
    "    #input('ENTER')\n",
    "\n",
    "\n",
    "    # Download the image locally\n",
    "    if overwrite_flag or (lst_file_name not in file_list):\n",
    "        print('  Downloading LST image from API')\n",
    "        if not os.path.isdir(year_folder):\n",
    "            os.makedirs(year_folder)\n",
    "            \n",
    "        with requests.get(lst_image_url, stream=True) as result:\n",
    "            result.raise_for_status()\n",
    "            with open(lst_local_path, 'wb') as f:\n",
    "                for chunk in result.iter_content(chunk_size=10000000):\n",
    "                    f.write(chunk)\n",
    "                    \n",
    "    if overwrite_flag or (qa_file_name not in file_list):\n",
    "        print('  Downloading QA image from API')\n",
    "        with requests.get(qa_image_url, stream=True) as result:\n",
    "            result.raise_for_status()\n",
    "            with open(qa_local_path, 'wb') as f:\n",
    "                for chunk in result.iter_content(chunk_size=10000000):\n",
    "                    f.write(chunk)\n",
    "\n",
    "    if ee.data.getInfo(asset_id):\n",
    "        if overwrite_flag:\n",
    "            print(f'  Asset already exists, removing')\n",
    "            try:\n",
    "                ee.data.deleteAsset(asset_id)\n",
    "            except Exception as e:\n",
    "                logging.exception(f'unhandled exception: {e}')\n",
    "                continue\n",
    "        else:\n",
    "            print(f'  Asset already exists and overwrite is False')\n",
    "            continue\n",
    "\n",
    "    \n",
    "    # Upload the image to the bucket\n",
    "    print('  Uploading to bucket')\n",
    "    bucket = storage_client.bucket(bucket_name)\n",
    "    lst_blob = bucket.blob(lst_bucket_path.replace(f'gs://{bucket_name}/', ''))\n",
    "    lst_blob.upload_from_filename(lst_local_path, timeout=120)\n",
    "    qa_blob = bucket.blob(qa_bucket_path.replace(f'gs://{bucket_name}/', ''))\n",
    "    qa_blob.upload_from_filename(qa_local_path, timeout=120)\n",
    "\n",
    "    \n",
    "    # Ingest into Earth Engine\n",
    "    print('  Ingesting into Earth Engine')\n",
    "    params = {\n",
    "        'name': asset_id,\n",
    "        'bands': [\n",
    "            {'id': lst_band_name, 'tilesetId': 'lst_image', 'tilesetBandIndex': 0},\n",
    "            {'id': qa_band_name, 'tilesetId': 'qa_image', 'tilesetBandIndex': 0},\n",
    "        ],\n",
    "        'tilesets': [\n",
    "            {'id': 'lst_image', 'sources': [{'uris': [lst_bucket_path]}]},\n",
    "            {'id': 'qa_image', 'sources': [{'uris': [qa_bucket_path]}]},\n",
    "        ],\n",
    "        'properties': properties,\n",
    "        'startTime': image_dt.isoformat(),\n",
    "        # 'startTime': image_dt.isoformat() + '.000000000Z',\n",
    "        # 'pyramiding_policy': 'MEAN',\n",
    "        # 'missingData': {'values': [nodata_value]},\n",
    "    }\n",
    "    task_id = ee.data.newTaskId()[0]\n",
    "    ee.data.startIngestion(task_id, params, allow_overwrite=True)\n",
    "\n",
    "    # break\n",
    "\n",
    "print('Done')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e023bb-d6c9-4ab2-800e-121518d8a898",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
