{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbbc425e-0064-4487-accd-aa47ecdc087e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import json\n",
    "# import logging\n",
    "import os\n",
    "import pprint\n",
    "import base64\n",
    "\n",
    "\n",
    "import ee\n",
    "from google.cloud import storage\n",
    "import pystac\n",
    "from pystac_client import Client\n",
    "import requests\n",
    "\n",
    "import IPython.display\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "endpoint = 'https://fusion-stac.hydrosat.com/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92327507-ef6f-45b3-b83e-bdae3f8467fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "ee.Initialize(project='dri-hydrosat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10cc0841-a06b-4658-9699-a57af07cd361",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get a new token (each day?) from here: https://stac.hydrosat.com/token\n",
    "# token = (\n",
    "#     ''\n",
    "# )\n",
    "# headers = {'Authorization': f'Bearer {token}'}\n",
    "\n",
    "# catalog = Client.open(endpoint, headers=headers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f6c0cc1-8d05-45ed-88f9-b568ffc4ef20",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('creds.json') as f:\n",
    "    creds = json.loads(f.read())\n",
    "\n",
    "userpass = f\"{creds['username']}:{creds['password']}\"\n",
    "b64 = base64.b64encode(userpass.encode()).decode()\n",
    "headers = {'Authorization':'Basic ' + b64}\n",
    "\n",
    "cat_url = 'https://stac.hydrosat.com'\n",
    "catalog = Client.open(cat_url, headers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c29d8fb-9b43-4bb9-b8da-071a361b60f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Replace with your username and password\n",
    "# userpass = 'username:password'\n",
    "# b64 = base64.b64encode(userpass.encode()).decode()\n",
    "# headers = {'Authorization':'Basic ' + b64}\n",
    "\n",
    "# catalog = Client.open('https://stac.hydrosat.com/', headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd9f268-3b5e-49b6-89dc-ee97e9eef931",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8174b06d-2ac9-4514-8c9e-166c7e73463e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get the list of collection\n",
    "# collections = catalog.get_children()\n",
    "# lst_collections = []\n",
    "# all_collections = []\n",
    "# for collection in collections:\n",
    "#     print(f\"{collection.id} - {collection.title}\")\n",
    "#     all_collections.append(collection.id)\n",
    "#     if \"lst\" in collection.title.lower() or \"temperature\" in collection.title.lower():\n",
    "#         lst_collections.append(collection.id)\n",
    "\n",
    "# # print('\\n')\n",
    "# # #for collection_id in sorted(lst_collections):\n",
    "# # for collection_id in sorted(all_collections):\n",
    "# #     print(collection_id)\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3844d1a3-122d-426b-b991-da23c68f8105",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "pydms_sharpened_ecostress - Sharpened LST using Sentinel-2 and ECOSTRESS\n",
    "prepped_inputs_s2 - Sentinel-2 Surface Reflectance\n",
    "starfm_predictions_viirs_landsat - Predicted LST using VIIRS and Landsat 8 or Landsat 9\n",
    "starfm_predictions_viirs_s2 - Predicted Surface Reflectance using VIIRS and Sentinel-2\n",
    "prepped_inputs_ecostress - ECOSTRESS Land Surface Temperature\n",
    "prepped_inputs_mod21a1d_evaluation - MODIS Land Surface Temperature MOD21\n",
    "pydms_sharpened_modis_evaluation - Sharpened LST using MODIS surface reflectance and LST\n",
    "prepped_inputs_mod09ga - MODIS Surface Reflectance MOD09GA\n",
    "pydms_sharpened_ecostress_evaluation - Sharpened LST using Sentinel-2 and ECOSTRESS\n",
    "pydms_sharpened_modis - Sharpened LST using MODIS surface reflectance and LST\n",
    "starfm_predictions_modis_ecostress - Predicted LST using MODIS and ECOSTRESS\n",
    "starfm_predictions_modis_s2_evaluation - Predicted Surface Reflectance using MODIS and Sentinel-2\n",
    "prepped_inputs_mod09ga_nrt_evaluation - MODIS Surface Reflectance MOD09GA_NRT\n",
    "prepped_inputs_ecostress_evaluation - ECOSTRESS Land Surface Temperature\n",
    "prepped_inputs_mod09ga_nrt - MODIS Surface Reflectance MOD09GA_NRT\n",
    "starfm_predictions_modis_landsat - Predicted LST using MODIS and Landsat 8 or Landsat 9\n",
    "pydms_sharpened_landsat_evaluation - Sharpened LST using Sentinel-2 and Landsat 8, or Sentinel-2 and Landsat 9\n",
    "prepped_inputs_landsat - Landsat 8 or Landsat 9 Surface Temperature\n",
    "prepped_inputs_mod21a1d - MODIS Land Surface Temperature MOD21\n",
    "starfm_predictions_modis_ecostress_evaluation - Predicted LST using MODIS and ECOSTRESS\n",
    "starfm_predictions_viirs_ecostress_evaluation - Predicted LST using VIIRS and ECOSTRESS\n",
    "starfm_predictions_viirs_ecostress - Predicted LST using VIIRS and ECOSTRESS\n",
    "starfm_predictions_modis_s2 - Predicted Surface Reflectance using MODIS and Sentinel-2\n",
    "prepped_inputs_vnp09ga_nrt - VIIRS Surface Reflectance VNP09GA_NRT\n",
    "prepped_inputs_mcd43a4 - MODIS Surface Reflectance MCD43\n",
    "prepped_inputs_landsat_evaluation - Landsat 8 or Landsat 9 Surface Temperature\n",
    "a - MODIS Surface Reflectance MOD09GA\n",
    "prepped_inputs_vnp21a1d - VIIRS Land Surface Temperature VNP21A1D\n",
    "starfm_predictions_viirs_landsat_evaluation - Predicted LST using VIIRS and Landsat 8 or Landsat 9\n",
    "prepped_inputs_mcd43a4_evaluation - MODIS Surface Reflectance MCD43\n",
    "prepped_inputs_vnp21a1d_evaluation - VIIRS Land Surface Temperature VNP21A1D\n",
    "prepped_inputs_vnp09ga_evaluation - VIIRS Surface Reflectance VNP09GA\n",
    "prepped_inputs_vnp43ia4_evaluation - VIIRS Surface Reflectance VNP43IA4\n",
    "pydms_sharpened_landsat - Sharpened LST using Sentinel-2 and Landsat 8, or Sentinel-2 and Landsat 9\n",
    "prepped_inputs_vnp09ga - VIIRS Surface Reflectance VNP09GA\n",
    "pydms_sharpened_viirs - Sharpened LST using VIIRS surface reflectance and LST\n",
    "prepped_inputs_vnp43ia4 - VIIRS Surface Reflectance VNP43IA4\n",
    "pydms_sharpened_viirs_evaluation - Sharpened LST using VIIRS surface reflectance and LST\n",
    "prepped_inputs_s2_evaluation - Sentinel-2 Surface Reflectance\n",
    "starfm_predictions_modis_landsat_evaluation - Predicted LST using MODIS and Landsat 8 or Landsat 9\n",
    "starfm_predictions_viirs_s2_evaluation - Predicted Surface Reflectance using VIIRS and Sentinel-2\n",
    "prepped_inputs_vnp09ga_nrt_evaluation - VIIRS Surface Reflectance VNP09GA_NRT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b71f436c-8eea-4e28-a0b1-435ea6aa18d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# search = catalog.search(\n",
    "#     bbox = [-111.51, 36.85, -110.36, 37.86],  # Powell\n",
    "#     datetime = [\"2019-01-01T00:00:00Z\", \"2020-01-01T00:00:00Z\"],\n",
    "#     collections = [\"starfm_predictions_modis_landsat\"],\n",
    "#     # intersects = {\"type\": \"Point\", \"coordinates\": [-120.0, 38.8]},  # Tahoe,\n",
    "#     # datetime = [\"2020-01-01T00:00:00Z\", \"2024-09-01T00:00:00Z\"],\n",
    "#     # collections = [\"starfm_predictions_viirs_landsat\"],\n",
    "#     max_items = 10,\n",
    "# )\n",
    "# items = search.item_collection()\n",
    "# itemjson = items.to_dict()\n",
    "# print(f'Number of catalog items: {len(items)}\\n')\n",
    "# IPython.display.JSON(itemjson)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b523510-684c-4cde-b170-a16934a8f97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # filepath = itemjson[\"features\"][1][\"assets\"][\"lst\"][\"href\"]\n",
    "# for item in itemjson[\"features\"]:\n",
    "#     filepath = item[\"assets\"][\"lst\"][\"href\"]\n",
    "#     print(filepath)\n",
    "    \n",
    "#     # # Open the file with Rasterio\n",
    "#     # import rasterio\n",
    "#     # from rasterio.windows import Window\n",
    "#     # from matplotlib import pyplot as plt\n",
    "#     # Session = rasterio.Env()\n",
    "    \n",
    "#     # with Session:\n",
    "#     #     with rasterio.open(filepath) as src:\n",
    "#     #         meta = src.meta\n",
    "#     #         tags = src.tags()\n",
    "#     #         print(meta)\n",
    "#     #         w = meta.get(\"width\")\n",
    "#     #         h = meta.get(\"height\")\n",
    "#     #         win = Window(w/6, h/6, 2000, 2000)\n",
    "#     #         data = src.read(1, window=win)\n",
    "#     #         data[data == meta['nodata']] = 0\n",
    "#     #         fig, ax = plt.subplots(1, 1, figsize=(12,12))\n",
    "#     #         plt.imshow(data, cmap='viridis')\n",
    "#     #         plt.colorbar(shrink=0.5)\n",
    "#     #         plt.show()\n",
    "#     break\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "626d6c27-b16f-451e-abfa-c7a5030e0749",
   "metadata": {},
   "outputs": [],
   "source": [
    "workspace = '/Users/Charles.Morton@dri.edu/Projects/hydrosat-assets/geotiffs/'\n",
    "# workspace = os.getcwd()\n",
    "\n",
    "project_id = 'dri-hydrosat'\n",
    "bucket_name = 'hydrosat'\n",
    "\n",
    "# Output band names\n",
    "lst_band_name = 'lst'\n",
    "qa_band_name = 'qa'\n",
    "\n",
    "overwrite_flag = False\n",
    "\n",
    "start_date = \"2019-01-01T00:00:00Z\"\n",
    "end_date = \"2020-01-01T00:00:00Z\"\n",
    "\n",
    "#aoi = {\"type\": \"Point\", \"coordinates\": [-120.0, 38.8]}     # Tahoe\n",
    "#aoi = {\"type\": \"Point\", \"coordinates\": [-111.3, 37.06]}    # Powell\n",
    "#aoi = {\"type\": \"Point\", \"coordinates\": [-114.75, 36.08]}   # Mead\n",
    "#aoi = {\"type\": \"Point\", \"coordinates\": [-114.65, 35.43]}   # Mojave\n",
    "bbaoi = [-111.51, 36.85, -110.36, 37.86]  # Powell\n",
    "\n",
    "collection = \"starfm_predictions_modis_landsat\"\n",
    "# collection = \"pydms_sharpened_landsat\"\n",
    "# collection = \"pydms_sharpened_modis\"\n",
    "# collection = \"pydms_sharpened_viirs\"\n",
    "print(f'Collection: {collection}\\n')\n",
    "\n",
    "search = catalog.search(\n",
    "    bbox = bbaoi,\n",
    "    #intersects = aoi,\n",
    "    datetime = [start_date, end_date],\n",
    "    collections = [collection],\n",
    "    max_items = 1000,\n",
    ")\n",
    "#items = search.get_all_items()\n",
    "items = search.item_collection()\n",
    "itemjson = items.to_dict()\n",
    "print(f'Number of catalog items: {len(items)}\\n')\n",
    "\n",
    "\n",
    "# Get the list of local file names (not paths)\n",
    "file_list = [\n",
    "    item\n",
    "    # os.path.join(root, item)\n",
    "    for root, dirs, files in os.walk(workspace, topdown=False)\n",
    "    for item in files\n",
    "    if item.endswith('.tif')\n",
    "]\n",
    "\n",
    "\n",
    "asset_coll = f'projects/{project_id}/assets/{collection}'\n",
    "if not ee.data.getInfo(asset_coll):\n",
    "    print('\\nCollection does not exist and will be built\\n  {}'.format(asset_coll))\n",
    "    input('Press ENTER to continue')\n",
    "    ee.data.createAsset({'type': 'IMAGE_COLLECTION'}, asset_coll)\n",
    "\n",
    "# TODO: Get the list of assets IDs instead of calling ee.data.getInfo in the loop\n",
    "# asset_id_list = ee.ImageCollection(asset_coll).aggregate_array('system:index').getInfo()\n",
    "\n",
    "\n",
    "storage_client = storage.Client(project=project_id)\n",
    "\n",
    "\n",
    "for item in itemjson[\"features\"]:\n",
    "\n",
    "    # pprint.pprint(item['assets'])\n",
    "    # break\n",
    "    \n",
    "    lst_image_url = item[\"assets\"][\"lst\"][\"href\"]\n",
    "    qa_image_url = item[\"assets\"][\"combined_qa\"][\"href\"]\n",
    "\n",
    "    collection = lst_image_url.split('?', 1)[0].split('/')[-4]\n",
    "    year = lst_image_url.split('?', 1)[0].split('/')[-3]\n",
    "    #temp = lst_image_url.split('?', 1)[0].split('/')[-2]\n",
    "    \n",
    "    lst_file_name = lst_image_url.split('?', 1)[0].split('/')[-1]\n",
    "    #.replace('.tif', f'_{lst_band_name}.tif')\n",
    "    qa_file_name = qa_image_url.split('?', 1)[0].split('/')[-1]\n",
    "    #.replace('.tif', f'_{qa_band_name}.tif')\n",
    "    print(f'{lst_file_name}')\n",
    "    print(f'{qa_file_name}')\n",
    "    # input('ENTER')\n",
    "\n",
    "    # DEADBEEF - Read these from properties\n",
    "    # # The file name structures are inconsistent between the collections\n",
    "    # #   so parse each one different depending on the collection (for now)\n",
    "    # # TODO: See if this data is available via the stac catalog somehow\n",
    "    # if collection == 'starfm_predictions_modis_landsat':\n",
    "    #     mgrs_tile = lst_file_name.split('_')[0]\n",
    "    #     image_dt = datetime.strptime(file_name.split('_')[2], '%Y%m%d')\n",
    "    #     source_dt = datetime.strptime(file_name.split('_')[4], '%Y%m%d')    \n",
    "    # elif collection in ['pydms_sharpened_landsat']:\n",
    "    #     # 'sharpened_11SKD_hires_lst_mosaic_screened_LC08_20200919_with_S2_11SKD_median_composite_20200920_screened.tif'\n",
    "    #     mgrs_tile = lst_file_name.split('_')[1]\n",
    "    #     image_dt = datetime.strptime(file_name.split('_')[7], '%Y%m%d')\n",
    "    #     source_dt = datetime.strptime(file_name.split('_')[13], '%Y%m%d')    \n",
    "    # elif collection in ['pydms_sharpened_modis']:\n",
    "    #     # 'sharpened_11SKD_lores_mosaic_MOD21A1D.061_20200930_with_11SKD_lores_mosaic_MCD43A4.006_20200930.tif'\n",
    "    #     mgrs_tile = lst_file_name.split('_')[1]\n",
    "    #     image_dt = datetime.strptime(file_name.split('_')[5], '%Y%m%d')\n",
    "    #     source_dt = datetime.strptime(file_name.replace('.tif', '').split('_')[11], '%Y%m%d')    \n",
    "        \n",
    "    year_folder = os.path.join(workspace, collection, year)\n",
    "    lst_local_path = os.path.join(year_folder, lst_file_name)\n",
    "    qa_local_path = os.path.join(year_folder, qa_file_name)\n",
    "    lst_bucket_path = f'gs://{bucket_name}/{collection}/{year}/{lst_file_name}'\n",
    "    qa_bucket_path = f'gs://{bucket_name}/{collection}/{year}/{qa_file_name}'\n",
    "    \n",
    "    image_dt = datetime.fromisoformat(item['properties']['datetime'])\n",
    "    image_id = f'{item[\"properties\"][\"mgrs_tile\"]}_{image_dt.strftime(\"%Y%m%d\")}'\n",
    "    asset_id = f'projects/{project_id}/assets/{collection}/{image_id}'\n",
    "    print(asset_id)\n",
    "\n",
    "\n",
    "    # Get the properties dictionary from the item\n",
    "    properties = item['properties']\n",
    "    properties['file_name'] = file_name\n",
    "    properties['date_ingested'] = f'{datetime.today().strftime(\"%Y-%m-%d\")}'\n",
    "\n",
    "    # Converting properties to string\n",
    "    # This is needed especially for the nested dictionary properties\n",
    "    # TODO: Check if JSON dump would be better for this\n",
    "    str_properties = [\n",
    "        'processing:time_of_day_range', 'processing:nrt', 'processing:overwrite_outputs',\n",
    "        'processing:public', 'processing:sr_only', 'processing:test_mode',\n",
    "        'processing:qa_screen_opts', 'processing:starfm_opts', \n",
    "        'processing:pydms_common_opts', 'processing:pydms_dt_opts', \n",
    "        'processing:starfm_opts', 'hydrosat:fusion_inputs',\n",
    "    ]\n",
    "    for p in str_properties:\n",
    "        if p in properties.keys():\n",
    "            properties[p] = str(properties[p])\n",
    "    \n",
    "    # TODO: Check for a cleaner way to rename properties in a dictionary\n",
    "    del_properties = [\n",
    "        'processing:software', 'processing:pydms_nn_opts', 'processing:pydms_sknn_opts', 'processing:lineage', \n",
    "    ]\n",
    "    new_properties = {}\n",
    "    for k, v in properties.items():\n",
    "        if ((\":\" in k) or ('-' in k)) and (k not in del_properties):\n",
    "            new_properties[k.replace(':', '_').replace('-', '_')] = v\n",
    "            del_properties.append(k)\n",
    "    for k in del_properties:\n",
    "        del properties[k] \n",
    "    properties.update(new_properties)\n",
    "    #pprint.pprint(properties)\n",
    "    #input('ENTER')\n",
    "\n",
    "\n",
    "    # Download the image locally\n",
    "    if overwrite_flag or (lst_file_name not in file_list):\n",
    "        print('  Downloading LST image from API')\n",
    "        if not os.path.isdir(year_folder):\n",
    "            os.makedirs(year_folder)\n",
    "            \n",
    "        with requests.get(lst_image_url, stream=True) as result:\n",
    "            result.raise_for_status()\n",
    "            with open(lst_local_path, 'wb') as f:\n",
    "                for chunk in result.iter_content(chunk_size=10000000):\n",
    "                    f.write(chunk)\n",
    "                    \n",
    "    if overwrite_flag or (qa_file_name not in file_list):\n",
    "        print('  Downloading QA image from API')\n",
    "        with requests.get(qa_image_url, stream=True) as result:\n",
    "            result.raise_for_status()\n",
    "            with open(qa_local_path, 'wb') as f:\n",
    "                for chunk in result.iter_content(chunk_size=10000000):\n",
    "                    f.write(chunk)\n",
    "\n",
    "    if ee.data.getInfo(asset_id):\n",
    "        if overwrite_flag:\n",
    "            print(f'  Asset already exists, removing')\n",
    "            try:\n",
    "                ee.data.deleteAsset(asset_id)\n",
    "            except Exception as e:\n",
    "                logging.exception(f'unhandled exception: {e}')\n",
    "                continue\n",
    "        else:\n",
    "            print(f'  Asset already exists and overwrite is False')\n",
    "            continue\n",
    "\n",
    "    \n",
    "    # Upload the image to the bucket\n",
    "    print('  Uploading to bucket')\n",
    "    bucket = storage_client.bucket(bucket_name)\n",
    "    lst_blob = bucket.blob(lst_bucket_path.replace(f'gs://{bucket_name}/', ''))\n",
    "    lst_blob.upload_from_filename(lst_local_path, timeout=120)\n",
    "    qa_blob = bucket.blob(qa_bucket_path.replace(f'gs://{bucket_name}/', ''))\n",
    "    qa_blob.upload_from_filename(qa_local_path, timeout=120)\n",
    "\n",
    "    \n",
    "    # Ingest into Earth Engine\n",
    "    print('  Ingesting into Earth Engine')\n",
    "    params = {\n",
    "        'name': asset_id,\n",
    "        'bands': [\n",
    "            {'id': lst_band_name, 'tilesetId': 'lst_image', 'tilesetBandIndex': 0},\n",
    "            {'id': qa_band_name, 'tilesetId': 'qa_image', 'tilesetBandIndex': 0},\n",
    "        ],\n",
    "        'tilesets': [\n",
    "            {'id': 'lst_image', 'sources': [{'uris': [lst_bucket_path]}]},\n",
    "            {'id': 'qa_image', 'sources': [{'uris': [qa_bucket_path]}]},\n",
    "        ],\n",
    "        'properties': properties,\n",
    "        'startTime': image_dt.isoformat(),\n",
    "        # 'startTime': image_dt.isoformat() + '.000000000Z',\n",
    "        # 'pyramiding_policy': 'MEAN',\n",
    "        # 'missingData': {'values': [nodata_value]},\n",
    "    }\n",
    "    task_id = ee.data.newTaskId()[0]\n",
    "    ee.data.startIngestion(task_id, params, allow_overwrite=True)\n",
    "\n",
    "    # break\n",
    "\n",
    "print('Done')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e023bb-d6c9-4ab2-800e-121518d8a898",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
